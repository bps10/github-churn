{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation on 2017 data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, Binarizer#, OneHotEncoderEstimator, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import to_timestamp, datediff, unix_timestamp\n",
    "\n",
    "import helper as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold events N: 600\n",
      "% of users dropped 2.96\n"
     ]
    }
   ],
   "source": [
    "churn_data = h.get_merged_data('validation', year='2017', user_year='2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data = h.add_high_low_flag(churn_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data = h.feature_scaling(churn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.3% of users churned in second period\n"
     ]
    }
   ],
   "source": [
    "h.print_user_churn(churn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'validate_2017'\n",
    "numeric_features = [t[0] for t in churn_data.dtypes if t[1] == 'int' or t[1] == 'double']\n",
    "\n",
    "if model_name is not 'nofilters':\n",
    "    numeric_features.remove('company')\n",
    "\n",
    "# These are the predictors/labels\n",
    "numeric_features.remove('second_period_event_count')\n",
    "numeric_features.remove('frequency')\n",
    "\n",
    "# These two are correlated w/ each other and most other events, therefore remove.\n",
    "if model_name is not 'nofilters':\n",
    "    numeric_features.remove('public_repos_count')\n",
    "    numeric_features.remove('public_gists_count')\n",
    "\n",
    "# Segmentation column\n",
    "numeric_features.remove('high_low_user')\n",
    "\n",
    "# Not predictive of anything\n",
    "numeric_features.remove('time_between_first_last_event')\n",
    "\n",
    "# Remove or binarize very rare events.\n",
    "numeric_features.remove('GollumEvent_count')\n",
    "numeric_features.remove('CommitCommentEvent_count')\n",
    "numeric_features.remove('MemberEvent_count')\n",
    "numeric_features.remove('PublicEvent_count')\n",
    "numeric_features.remove('ReleaseEvent_count')\n",
    "numeric_features += ['PublicEvent_count_bin']\n",
    "numeric_features += ['ReleaseEvent_count_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Models loaded-----\n",
      "-----Pipeline loaded-----\n"
     ]
    }
   ],
   "source": [
    "# Load PySpark pipeline and model\n",
    "spark = SparkSession.builder.appName('App').getOrCreate()\n",
    "\n",
    "LRmodelNoFilter = LogisticRegressionModel.load(\"lrModel_nofilters\")\n",
    "LRmodelCompany = LogisticRegressionModel.load(\"lrModel_company_1\")\n",
    "LRmodelLow = LogisticRegressionModel.load(\"lrModel_company_0high_low_0\")\n",
    "LRmodelHigh = LogisticRegressionModel.load(\"lrModel_company_0high_low_1\")\n",
    "\n",
    "print('-----Models loaded-----')\n",
    "pipeline = Pipeline.load('pipeline')\n",
    "print('-----Pipeline loaded-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebalance data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N churned users 1947\n",
      "N active users 1908\n"
     ]
    }
   ],
   "source": [
    "churners = churn_data.filter(churn_data.second_period_event_count < 1)\n",
    "churn_count = churners.count()\n",
    "\n",
    "active = churn_data.filter(churn_data.second_period_event_count > 0)\n",
    "active_count = active.count()\n",
    "\n",
    "active = active.sample(False, churn_count / active_count, seed=0)\n",
    "\n",
    "balanced_data = churners.union(active)\n",
    "\n",
    "print('N churned users {0}'.format(churn_count))\n",
    "print('N active users {0}'.format(active.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate(data, model):\n",
    "    data = data.withColumn(\"second_period_event_count\", \n",
    "        data.second_period_event_count.cast(DoubleType())\n",
    "        )\n",
    "    pipelineModel = pipeline.fit(data)\n",
    "    usr_data = pipelineModel.transform(data)\n",
    "    prediction = model.transform(usr_data)\n",
    "    prediction = prediction.select(['login', 'probability', 'label',\n",
    "                                    'prediction']).toPandas()\n",
    "\n",
    "    prediction['probability'] = prediction.probability.apply(lambda x: x[1])\n",
    "    h.eval_metrics(prediction.prediction, prediction.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP, FN | FP, TN\n",
      "1417, 480 | 565, 1361\n",
      "---------------------------\n",
      "Precision: 0.715\n",
      "Recall:    0.747\n",
      "Accuracy:  0.727\n",
      "F1-score:  0.7306\n"
     ]
    }
   ],
   "source": [
    "predict_and_evaluate(balanced_data, LRmodelNoFilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_users = balanced_data[balanced_data.company == 1]\n",
    "old = balanced_data[(balanced_data.high_low_user == 1) & (balanced_data.company == 0)]\n",
    "new = balanced_data[(balanced_data.high_low_user == 0) & (balanced_data.company == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP, FN | FP, TN\n",
      "360, 21 | 77, 27\n",
      "---------------------------\n",
      "Precision: 0.824\n",
      "Recall:    0.945\n",
      "Accuracy:  0.798\n",
      "F1-score:  0.8802\n"
     ]
    }
   ],
   "source": [
    "predict_and_evaluate(company_users, LRmodelCompany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP, FN | FP, TN\n",
      "2, 52 | 4, 471\n",
      "---------------------------\n",
      "Precision: 0.333\n",
      "Recall:    0.037\n",
      "Accuracy:  0.894\n",
      "F1-score:  0.0667\n"
     ]
    }
   ],
   "source": [
    "predict_and_evaluate(new, LRmodelLow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP, FN | FP, TN\n",
      "1095, 367 | 512, 835\n",
      "---------------------------\n",
      "Precision: 0.681\n",
      "Recall:    0.749\n",
      "Accuracy:  0.687\n",
      "F1-score:  0.7136\n"
     ]
    }
   ],
   "source": [
    "predict_and_evaluate(old, LRmodelHigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
